<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 1 Basic statistical results | Econometrics and Statistics</title>
<meta name="author" content="Jean-Paul Renne">
<meta name="description" content="1.1 Cumulative and probability density funtions (c.d.f. and p.d.f.)  Definition 1.1 (Cumulative distribution function (c.d.f.)) The random variable (r.v.) \(X\) admits the cumulative distribution...">
<meta name="generator" content="bookdown 0.27 with bs4_book()">
<meta property="og:title" content="Chapter 1 Basic statistical results | Econometrics and Statistics">
<meta property="og:type" content="book">
<meta property="og:description" content="1.1 Cumulative and probability density funtions (c.d.f. and p.d.f.)  Definition 1.1 (Cumulative distribution function (c.d.f.)) The random variable (r.v.) \(X\) admits the cumulative distribution...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapter 1 Basic statistical results | Econometrics and Statistics">
<meta name="twitter:description" content="1.1 Cumulative and probability density funtions (c.d.f. and p.d.f.)  Definition 1.1 (Cumulative distribution function (c.d.f.)) The random variable (r.v.) \(X\) admits the cumulative distribution...">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><script src="libs/bs3compat-0.4.0/transition.js"></script><script src="libs/bs3compat-0.4.0/tabs.js"></script><script src="libs/bs3compat-0.4.0/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
<style type="text/css">
    /* Used with Pandoc 2.11+ new --citeproc when CSL is used */
    div.csl-bib-body { }
    div.csl-entry {
      clear: both;
        }
    .hanging div.csl-entry {
      margin-left:2em;
      text-indent:-2em;
    }
    div.csl-left-margin {
      min-width:2em;
      float:left;
    }
    div.csl-right-inline {
      margin-left:2em;
      padding-left:1em;
    }
    div.csl-indent {
      margin-left: 2em;
    }
  </style>
<link rel="stylesheet" href="my-style.css">
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Econometrics and Statistics</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html">Econometrics and statistics</a></li>
<li><a class="active" href="Basics.html"><span class="header-section-number">1</span> Basic statistical results</a></li>
<li><a class="" href="TCL.html"><span class="header-section-number">2</span> Central Limit Theorem</a></li>
<li><a class="" href="Tests.html"><span class="header-section-number">3</span> Statistical tests</a></li>
<li><a class="" href="ChapterLS.html"><span class="header-section-number">4</span> Linear Regressions</a></li>
<li><a class="" href="Panel.html"><span class="header-section-number">5</span> Panel regressions</a></li>
<li><a class="" href="estimation-methods.html"><span class="header-section-number">6</span> Estimation Methods</a></li>
<li><a class="" href="microeconometrics.html"><span class="header-section-number">7</span> Microeconometrics</a></li>
<li><a class="" href="TS.html"><span class="header-section-number">8</span> Time Series</a></li>
<li><a class="" href="append.html"><span class="header-section-number">9</span> Appendix</a></li>
<li><a class="" href="references.html">References</a></li>
</ul>

        <div class="book-extra">
          
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="Basics" class="section level1" number="1">
<h1>
<span class="header-section-number">1</span> Basic statistical results<a class="anchor" aria-label="anchor" href="#Basics"><i class="fas fa-link"></i></a>
</h1>
<div id="cumulative-and-probability-density-funtions-c.d.f.-and-p.d.f." class="section level2" number="1.1">
<h2>
<span class="header-section-number">1.1</span> Cumulative and probability density funtions (c.d.f. and p.d.f.)<a class="anchor" aria-label="anchor" href="#cumulative-and-probability-density-funtions-c.d.f.-and-p.d.f."><i class="fas fa-link"></i></a>
</h2>
<div class="definition">
<p><span id="def:cdf" class="definition"><strong>Definition 1.1  (Cumulative distribution function (c.d.f.)) </strong></span>The random variable (r.v.) <span class="math inline">\(X\)</span> admits the cumulative distribution function <span class="math inline">\(F\)</span> if, for all <span class="math inline">\(a\)</span>:
<span class="math display">\[
F(a)=\mathbb{P}(X \le a).
\]</span></p>
</div>
<div class="definition">
<p><span id="def:pdf" class="definition"><strong>Definition 1.2  (Probability distribution function (p.d.f.)) </strong></span>A continuous random variable <span class="math inline">\(X\)</span> admits the probability density function <span class="math inline">\(f\)</span> if, for all <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span> such that <span class="math inline">\(a&lt;b\)</span>:
<span class="math display">\[
\mathbb{P}(a &lt; X \le b) = \int_{a}^{b}f(x)dx,
\]</span>
where <span class="math inline">\(f(x) \ge 0\)</span> for all <span class="math inline">\(x\)</span>.</p>
</div>
<p>In particular, we have:
<span class="math display" id="eq:flim">\[\begin{equation}
f(x) = \lim_{\varepsilon \rightarrow 0} \frac{\mathbb{P}(x &lt; X \le x + \varepsilon)}{\varepsilon} = \lim_{\varepsilon \rightarrow 0} \frac{F(x + \varepsilon)-F(x)}{\varepsilon}.\tag{1.1}
\end{equation}\]</span>
and
<span class="math display">\[
F(a) = \int_{-\infty}^{a}f(x)dx.
\]</span>
This <a href="https://jrenne.shinyapps.io/density/">web interface</a> illustrates the link between p.d.f. and c.d.f. Nonparametric estimates of p.d.f. are obtained by kernel-based methods (see this <a href="https://www.dropbox.com/s/lxkllp9yewh98d8/Additional_Kernel.pdf?dl=0">extra material</a>).</p>
<div class="definition">
<p><span id="def:jointcdf" class="definition"><strong>Definition 1.3  (Joint cumulative distribution function (c.d.f.)) </strong></span>The random variables <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> admit the joint cumulative distribution function <span class="math inline">\(F_{XY}\)</span> if, for all <span class="math inline">\(a\)</span> and <span class="math inline">\(b\)</span>:
<span class="math display">\[
F_{XY}(a,b)=\mathbb{P}(X \le a,Y \le b).
\]</span></p>
</div>
<div class="figure" style="text-align: left-aligned">
<span style="display:block;" id="fig:essai3d2"></span>
<img src="EcoStat_files/figure-html/essai3d2-1.png" alt="The volume between the horizontal plane ($z=0$) and the surface is equal to $F_{XY}(0.5,1)=\mathbb{P}(X&lt;0.5,Y&lt;1)$." width="95%"><p class="caption">
Figure 1.1: The volume between the horizontal plane (<span class="math inline">\(z=0\)</span>) and the surface is equal to <span class="math inline">\(F_{XY}(0.5,1)=\mathbb{P}(X&lt;0.5,Y&lt;1)\)</span>.
</p>
</div>
<div class="definition">
<p><span id="def:jointpdf" class="definition"><strong>Definition 1.4  (Joint probability density function (p.d.f.)) </strong></span>The continuous random variables <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> admit the joint p.d.f. <span class="math inline">\(f_{XY}\)</span>, where <span class="math inline">\(f_{XY}(x,y) \ge 0\)</span> for all <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span>, if:
<span class="math display">\[
\mathbb{P}(a &lt; X \le b,c &lt; Y \le d) = \int_{a}^{b}\int_{c}^{d}f_{XY}(x,y)dx dy, \quad \forall a \le b,\;c \le d.
\]</span></p>
</div>
<p>In particular, we have:
<span class="math display">\[\begin{eqnarray*}
&amp;&amp;f_{XY}(x,y)\\
&amp;=&amp; \lim_{\varepsilon \rightarrow 0} \frac{\mathbb{P}(x &lt; X \le x + \varepsilon,y &lt; Y \le y + \varepsilon)}{\varepsilon^2} \\
&amp;=&amp; \lim_{\varepsilon \rightarrow 0} \frac{F_{XY}(x + \varepsilon,y + \varepsilon)-F_{XY}(x,y + \varepsilon)-F_{XY}(x + \varepsilon,y)+F_{XY}(x,y)}{\varepsilon^2}.
\end{eqnarray*}\]</span></p>
<div class="figure" style="text-align: left-aligned">
<span style="display:block;" id="fig:essai3d"></span>
<img src="EcoStat_files/figure-html/essai3d-1.png" alt="Assume that the basis of the black column is defined by those points whose $x$-coordinates are between $x$ and $x+\varepsilon$ and $y$-coordinates are between $y$ and $y+\varepsilon$. Then the volume of the black column is equal to $\mathbb{P}(x &lt; X \le x+\varepsilon,y &lt; Y \le y+\varepsilon)$, which is approximately equal to $f_{XY}(x,y)\varepsilon^2$ if $\varepsilon$ is small." width="95%"><p class="caption">
Figure 1.2: Assume that the basis of the black column is defined by those points whose <span class="math inline">\(x\)</span>-coordinates are between <span class="math inline">\(x\)</span> and <span class="math inline">\(x+\varepsilon\)</span> and <span class="math inline">\(y\)</span>-coordinates are between <span class="math inline">\(y\)</span> and <span class="math inline">\(y+\varepsilon\)</span>. Then the volume of the black column is equal to <span class="math inline">\(\mathbb{P}(x &lt; X \le x+\varepsilon,y &lt; Y \le y+\varepsilon)\)</span>, which is approximately equal to <span class="math inline">\(f_{XY}(x,y)\varepsilon^2\)</span> if <span class="math inline">\(\varepsilon\)</span> is small.
</p>
</div>
<div class="definition">
<p><span id="def:condcdf" class="definition"><strong>Definition 1.5  (Conditional probability distribution function) </strong></span>If <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are continuous r.v., then the distribution of <span class="math inline">\(X\)</span> conditional on <span class="math inline">\(Y=y\)</span>, which we denote by <span class="math inline">\(f_{X|Y}(x,y)\)</span>, satisfies:
<span class="math display">\[
f_{X|Y}(x,y)=\lim_{\varepsilon \rightarrow 0} \frac{\mathbb{P}(x &lt; X \le x + \varepsilon|Y=y)}{\varepsilon}.
\]</span></p>
</div>
<div class="proposition">
<p><span id="prp:condcdf" class="proposition"><strong>Proposition 1.1  (Conditional probability distribution function) </strong></span>We have
<span class="math display">\[
f_{X|Y}(x,y)=\frac{f_{XY}(x,y)}{f_Y(y)}.
\]</span></p>
</div>
<div class="proof">
<p><span id="unlabeled-div-1" class="proof"><em>Proof</em>. </span>We have:
<span class="math display">\[\begin{eqnarray*}
f_{X|Y}(x,y)&amp;=&amp;\lim_{\varepsilon \rightarrow 0} \frac{\mathbb{P}(x &lt; X \le x + \varepsilon|Y=y)}{\varepsilon}\\
&amp;=&amp;\lim_{\varepsilon \rightarrow 0} \frac{1}{\varepsilon}\mathbb{P}(x &lt; X \le x + \varepsilon|y&lt;Y\le y+\varepsilon)\\
&amp;=&amp;\lim_{\varepsilon \rightarrow 0} \frac{1}{\varepsilon}\frac{\mathbb{P}(x &lt; X \le x + \varepsilon,y&lt;Y\le y+\varepsilon)}{\mathbb{P}(y&lt;Y\le y+\varepsilon)}\\
&amp;=&amp;\lim_{\varepsilon \rightarrow 0} \frac{1}{\varepsilon} \frac{\varepsilon^2f_{XY}(x,y)}{\varepsilon f_{Y}(y)}.
\end{eqnarray*}\]</span></p>
</div>
<div class="definition">
<p><span id="def:independent" class="definition"><strong>Definition 1.6  (Independent random variables) </strong></span>Consider two r.v., <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span>, with respective c.d.f. <span class="math inline">\(F_X\)</span> and <span class="math inline">\(F_Y\)</span>, and respective p.d.f. <span class="math inline">\(f_X\)</span> and <span class="math inline">\(f_Y\)</span>.</p>
<p>These random variables are independent if and only if (iff) the joint c.d.f. of <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> (see Def. <a href="Basics.html#def:jointcdf">1.3</a>) is given by:
<span class="math display">\[
F_{XY}(x,y) = F_{X}(x) \times F_{Y}(y),
\]</span>
or, equivalently, iff the joint p.d.f. of <span class="math inline">\((X,Y)\)</span> (see Def. <a href="Basics.html#def:jointpdf">1.4</a>) is given by:
<span class="math display">\[
f_{XY}(x,y) = f_{X}(x) \times f_{Y}(y).
\]</span></p>
</div>
<p>We have the following:</p>
<ol style="list-style-type: decimal">
<li>If <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are independent, <span class="math inline">\(f_{X|Y}(x,y)=f_{X}(x)\)</span>. This implies, in particular, that <span class="math inline">\(\mathbb{E}(g(X)|Y)=\mathbb{E}(g(X))\)</span>, where <span class="math inline">\(g\)</span> is any function.</li>
<li>If <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are independent, then <span class="math inline">\(\mathbb{E}(g(X)h(Y))=\mathbb{E}(g(X))\mathbb{E}(h(Y))\)</span> and <span class="math inline">\(\mathbb{C}ov(g(X),h(Y))=0\)</span>, where <span class="math inline">\(g\)</span> and <span class="math inline">\(h\)</span> are any functions.</li>
</ol>
<p>It is important to note that the absence of correlation between two variables is not a sufficient condition to have independence. Consider for instance the case where <span class="math inline">\(X=Y^2\)</span>, with <span class="math inline">\(Y \sim\mathcal{N}(0,1)\)</span>. In this case, we have <span class="math inline">\(\mathbb{C}ov(X,Y)=0\)</span>, but <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are not independent. Indeed, we have for instance <span class="math inline">\(\mathbb{E}(Y^2 \times X)=3\)</span>, which is not equal to <span class="math inline">\(\mathbb{E}(Y^2) \times \mathbb{E}(X)=1\)</span>. (If <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> were independent, we should have <span class="math inline">\(\mathbb{E}(Y^2 \times X)=\mathbb{E}(Y^2) \times \mathbb{E}(X)\)</span> according to point 2 above.)</p>
</div>
<div id="law-of-iterated-expectations" class="section level2" number="1.2">
<h2>
<span class="header-section-number">1.2</span> Law of iterated expectations<a class="anchor" aria-label="anchor" href="#law-of-iterated-expectations"><i class="fas fa-link"></i></a>
</h2>
<div class="proposition">
<p><span id="prp:lawiteratedexpect" class="proposition"><strong>Proposition 1.2  (Law of iterated expectations) </strong></span>If <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are two random variables and if <span class="math inline">\(\mathbb{E}(|X|)&lt;\infty\)</span>, we have:
<span class="math display">\[
\boxed{\mathbb{E}(X) = \mathbb{E}(\mathbb{E}(X|Y)).}
\]</span></p>
</div>
<div class="proof">
<p><span id="unlabeled-div-2" class="proof"><em>Proof</em>. </span>(in the case where the p.d.f. of <span class="math inline">\((X,Y)\)</span> exists) Let us denote by <span class="math inline">\(f_X\)</span>, <span class="math inline">\(f_Y\)</span> and <span class="math inline">\(f_{XY}\)</span> the probability distribution functions (p.d.f.) of <span class="math inline">\(X\)</span>, <span class="math inline">\(Y\)</span> and <span class="math inline">\((X,Y)\)</span>, respectively. We have:
<span class="math display">\[
f_{X}(x) = \int f_{XY}(x,y) dy.
\]</span>
Besides, we have (Bayes equality, Prop. <a href="Basics.html#prp:condcdf">1.1</a>):
<span class="math display">\[
f_{XY}(x,y) = f_{X|Y}(x,y)f_{Y}(y).
\]</span>
Therefore:
<span class="math display">\[\begin{eqnarray*}
\mathbb{E}(X) &amp;=&amp; \int x f_X(x)dx = \int x  \underbrace{ \int  f_{XY}(x,y) dy}_{=f_X(x)} dx =\int  \int x f_{X|Y}(x,y)f_{Y}(y) dydx \\
&amp; = &amp; \int \underbrace{\left(\int x f_{X|Y}(x,y)dx\right)}_{\mathbb{E}[X|Y=y]}f_{Y}(y) dy = \mathbb{E} \left( \mathbb{E}[X|Y] \right).
\end{eqnarray*}\]</span></p>
</div>
<div class="example">
<p><span id="exm:mixture" class="example"><strong>Example 1.1  (Mixture of Gaussian distributions) </strong></span>By definition, <span class="math inline">\(X\)</span> is drawn from a mixture of Gaussian distributions if:
<span class="math display">\[
X = \color{blue}{B \times Y_1} + \color{red}{(1-B) \times Y_2},
\]</span>
where <span class="math inline">\(B\)</span>, <span class="math inline">\(Y_1\)</span> and <span class="math inline">\(Y_2\)</span> are three independent variables drawn as follows:
<span class="math display">\[
B \sim \mbox{Bernoulli}(p),\quad Y_1 \sim \mathcal{N}(\mu_1,\sigma_1^2), \quad \mbox{and}\quad Y_2 \sim \mathcal{N}(\mu_2,\sigma_2^2).
\]</span></p>
<p>Figure <a href="Basics.html#fig:mixtureG">1.3</a> displays the pdfs associated with three different mixtures of Gaussian distributions. (This <a href="https://jrenne.shinyapps.io/density/">web-interface</a> allows to produce the pdf associated for any other parameterization.)</p>
<div class="figure" style="text-align: left-aligned">
<span style="display:block;" id="fig:mixtureG"></span>
<img src="EcoStat_files/figure-html/mixtureG-1.png" alt="Example of pdfs of mixtures of Gaussian distribututions." width="95%"><p class="caption">
Figure 1.3: Example of pdfs of mixtures of Gaussian distribututions.
</p>
</div>
<p>The law of iterated expectations gives:
<span class="math display">\[
\mathbb{E}(X) = \mathbb{E}(\mathbb{E}(X|B)) = \mathbb{E}(B\mu_1+(1-B)\mu_2)=p\mu_1 + (1-p)\mu_2.
\]</span></p>
</div>
<div class="example">
<p><span id="exm:Buffon" class="example"><strong>Example 1.2  (Buffon (1733)'s needles) </strong></span>Suppose we have a floor made of parallel strips of wood, each the same width [<span class="math inline">\(w=1\)</span>]. We drop a needle, of length <span class="math inline">\(1/2\)</span>, onto the floor. What is the probability that the needle crosses the grooves of the floor?</p>
<p>Let’s define the random variable <span class="math inline">\(X\)</span> by
<span class="math display">\[
X = \left\{
\begin{array}{cl}
1 &amp; \mbox{if the needle crosses a line}\\
0 &amp; \mbox{otherwise.}
\end{array}
\right.
\]</span>
Conditionally on <span class="math inline">\(\theta\)</span>, it can be seen that we have <span class="math inline">\(\mathbb{E}(X|\theta)=\cos(\theta)/2\)</span> (see Figure <a href="Basics.html#fig:Buffon">1.4</a>).</p>
<div class="figure" style="text-align: left-aligned">
<span style="display:block;" id="fig:Buffon"></span>
<img src="EcoStat_files/figure-html/Buffon-1.png" alt="Schematic representation of the problem." width="95%"><p class="caption">
Figure 1.4: Schematic representation of the problem.
</p>
</div>
<p>It is reasonable to assume that <span class="math inline">\(\theta\)</span> is uniformly distributed on <span class="math inline">\([-\pi/2,\pi/2]\)</span>, therefore:
<span class="math display">\[
\mathbb{E}(X)=\mathbb{E}(\mathbb{E}(X|\theta))=\mathbb{E}(\cos(\theta)/2)=\int_{-\pi/2}^{\pi/2}\frac{1}{2}\cos(\theta)\left(\frac{d\theta}{\pi}\right)=\frac{1}{\pi}.
\]</span></p>
<p>[This <a href="https://jrenne.shinyapps.io/StatEcoII/">web-interface</a> allows to simulate the present experiment (select Worksheet “Buffon’s needles”).]</p>
</div>
<!-- \begin{exmpl}[Davis and Lo's (2001) model] -->
<!-- \href{http://www.tandfonline.com/doi/abs/10.1080/713665832}{Davis and Lo (2001)} introduce a contagion model and propose applications in terms of credit-risk management. -->
<!-- \vspace{.2cm} -->
<!-- They consider $n$ entities. The state of entity $i$ is denoted by $d_i$: $d_i=0$ if entity $i$ stays non-infected and $1$ if it gets infected. There are two ways of getting infected: -->
<!-- \begin{itemize} -->
<!--    \item direct, or autonomous, infection; -->
<!--    \item indirect infection, or contamination. -->
<!-- \end{itemize} -->
<!-- \vspace{.2cm} -->
<!-- Direct infection and contamination are modelled through two types of random variables: $X_i$s ($n$ of them) and $Y_{ji}$s ($n^2$ of them). These $n(n+1)$ variables are independently Bernoulli distributed. The Bernoulli parameter is $p$ for the $X_i$s and $q$ for the $Y_{ji}$s. We have: -->
<!-- $$ -->
<!-- d_i = \underbrace{X_i}_{\mbox{autonomous infection}} + (1 - X_i) \underbrace{\left(1 - \prod_{j \ne i}(1 - X_jY_{ji})\right)}_{\mbox{contamination}}. -->
<!-- $$ -->
<!-- In order to determine the distribution of the number of infected entities, it is convenient to first reason conditionally on the number of autonomous infections $r$ defined by $r=\sum_i X_i $. \href{https://jrenne.shinyapps.io/StatEcoII/}{\beamergotobutton{Web-interface illustration}} -->
<!-- \end{exmpl} -->
</div>
<div id="law-of-total-variance" class="section level2" number="1.3">
<h2>
<span class="header-section-number">1.3</span> Law of total variance<a class="anchor" aria-label="anchor" href="#law-of-total-variance"><i class="fas fa-link"></i></a>
</h2>
<div class="proposition">
<p><span id="prp:lawtotalvariance" class="proposition"><strong>Proposition 1.3  (Law of total variance) </strong></span>If <span class="math inline">\(X\)</span> and <span class="math inline">\(Y\)</span> are two random variables and if the variance of <span class="math inline">\(X\)</span> is finite, we have:
<span class="math display">\[
\boxed{\mathbb{V}ar(X) = \mathbb{E}(\mathbb{V}ar(X|Y)) + \mathbb{V}ar(\mathbb{E}(X|Y)).}
\]</span></p>
</div>
<div class="proof">
<p><span id="unlabeled-div-3" class="proof"><em>Proof</em>. </span>We have:
<span class="math display">\[\begin{eqnarray*}
\mathbb{V}ar(X) &amp;=&amp; \mathbb{E}(X^2) - \mathbb{E}(X)^2\\
&amp;=&amp; \mathbb{E}(\mathbb{E}(X^2|Y)) - \mathbb{E}(X)^2\\
&amp;=&amp; \mathbb{E}(\mathbb{E}(X^2|Y) \color{blue}{- \mathbb{E}(X|Y)^2}) +  \color{blue}{\mathbb{E}(\mathbb{E}(X|Y)^2)}  - \color{red}{\mathbb{E}(X)^2}\\
&amp;=&amp; \mathbb{E}(\underbrace{\mathbb{E}(X^2|Y) - \mathbb{E}(X|Y)^2}_{\mathbb{V}ar(X|Y)}) + \underbrace{\mathbb{E}(\mathbb{E}(X|Y)^2) - \color{red}{\mathbb{E}(\mathbb{E}(X|Y))^2}}_{\mathbb{V}ar(\mathbb{E}(X|Y))}.
\end{eqnarray*}\]</span></p>
</div>
<div class="example">
<p><span id="exm:mixture2" class="example"><strong>Example 1.3  (Mixture of Gaussian distributions (cont'd)) </strong></span>Consider the case of a mixture of Gaussian distributions (Example <a href="Basics.html#exm:mixture">1.1</a>). We have:
<span class="math display">\[\begin{eqnarray*}
\mathbb{V}ar(X) &amp;=&amp; \color{blue}{\mathbb{E}(\mathbb{V}ar(X|B))} + \color{red}{\mathbb{V}ar(\mathbb{E}(X|B))}\\
&amp;=&amp;  \color{blue}{p\sigma_1^2+(1-p)\sigma_2^2} + \color{red}{p(1-p)(\mu_1 - \mu_2)^2}.
\end{eqnarray*}\]</span></p>
</div>
<!-- \end{footnotesize} -->
</div>
<div id="about-consistent-estimators" class="section level2" number="1.4">
<h2>
<span class="header-section-number">1.4</span> About consistent estimators<a class="anchor" aria-label="anchor" href="#about-consistent-estimators"><i class="fas fa-link"></i></a>
</h2>
<p>The objective of econometrics is to estimate parameters out of data observations (samples). Examples of parameters of interest include, among many others: causal effect of a variable on another, elasticities, parameters defining some distribution of interest, preference parameters (risk aversion)…</p>
<p>Except in degenerate cases, the estimates are different from the “true” (or <em>population</em>) value. A good estimator is expected to converge to the true value when the sample size increases. That is, we are interested in the <em>consistency</em> of the estimator.</p>
<p>Denote by <span class="math inline">\(\hat\theta_n\)</span> the estimate of <span class="math inline">\(\theta\)</span> based on a sample of length <span class="math inline">\(n\)</span>. We say that <span class="math inline">\(\hat\theta\)</span> is a consistent estimator of <span class="math inline">\(\theta\)</span> if, for any <span class="math inline">\(\varepsilon&gt;0\)</span> (even if very small), the probability that <span class="math inline">\(\hat\theta_n\)</span> is in <span class="math inline">\([\theta - \varepsilon,\theta + \varepsilon]\)</span> goes to 1 when <span class="math inline">\(n\)</span> goes to <span class="math inline">\(\infty\)</span>. Formally:
<span class="math display">\[
\lim_{n \rightarrow + \infty} \mathbb{P}\left(\hat\theta_n \in [\theta - \varepsilon,\theta + \varepsilon]\right) = 1.
\]</span></p>
<p>That is, <span class="math inline">\(\hat\theta\)</span> is a consistent estimator if <span class="math inline">\(\hat\theta_n\)</span> <em>converges in probability</em> (Def. <a href="append.html#def:convergenceproba">9.14</a>) to <span class="math inline">\(\theta\)</span>. Note that there exist different types of stochastic convergence.<a class="footnote-ref" tabindex="0" data-toggle="popover" data-content='&lt;p&gt;Appendix &lt;a href="append.html#StochConvergences"&gt;9.3.3&lt;/a&gt; notably provides the definitions of the convergence in distribution (Def. &lt;a href="append.html#def:cvgceDistri"&gt;9.17&lt;/a&gt;) and the mean-square convergence (Def. &lt;a href="append.html#def:convergenceLr"&gt;9.15&lt;/a&gt;).&lt;/p&gt;'><sup>1</sup></a></p>
<div class="example">
<p><span id="exm:NonConsist" class="example"><strong>Example 1.4  (Example of non-convergent estimator) </strong></span>Assume that <span class="math inline">\(X_i \sim i.i.d. \mbox{Cauchy}\)</span> with a location parameter of 1 and a scale parameter of 1 (Def. <a href="append.html#def:Cauchy">9.12</a>). The sample mean <span class="math inline">\(\bar{X}_n = \frac{1}{n}\sum_{i=1}^{n} X_i\)</span> does not converge in probability. This is because a Cauchy distribution has no mean; hence the law of large numbers (Theorem <a href="TCL.html#thm:LLN">2.1</a>) does not apply.</p>
<div class="figure" style="text-align: left-aligned">
<span style="display:block;" id="fig:figCauchy"></span>
<img src="EcoStat_files/figure-html/figCauchy-1.png" alt="Simulation of $\bar{X}_n$ when $X_i \sim i.i.d. \mbox{Cauchy}$." width="95%"><p class="caption">
Figure 1.5: Simulation of <span class="math inline">\(\bar{X}_n\)</span> when <span class="math inline">\(X_i \sim i.i.d. \mbox{Cauchy}\)</span>.
</p>
</div>
</div>

</div>
</div>

  <div class="chapter-nav">
<div class="prev"><a href="index.html">Econometrics and statistics</a></div>
<div class="next"><a href="TCL.html"><span class="header-section-number">2</span> Central Limit Theorem</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav">
<li><a class="nav-link" href="#Basics"><span class="header-section-number">1</span> Basic statistical results</a></li>
<li><a class="nav-link" href="#cumulative-and-probability-density-funtions-c.d.f.-and-p.d.f."><span class="header-section-number">1.1</span> Cumulative and probability density funtions (c.d.f. and p.d.f.)</a></li>
<li><a class="nav-link" href="#law-of-iterated-expectations"><span class="header-section-number">1.2</span> Law of iterated expectations</a></li>
<li><a class="nav-link" href="#law-of-total-variance"><span class="header-section-number">1.3</span> Law of total variance</a></li>
<li><a class="nav-link" href="#about-consistent-estimators"><span class="header-section-number">1.4</span> About consistent estimators</a></li>
</ul>

      <div class="book-extra">
        <ul class="list-unstyled">
          
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Econometrics and Statistics</strong>" was written by Jean-Paul Renne. It was last built on 2023-01-13.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer><!-- dynamically load mathjax for compatibility with self-contained --><script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script><script type="text/x-mathjax-config">const popovers = document.querySelectorAll('a.footnote-ref[data-toggle="popover"]');
for (let popover of popovers) {
  const div = document.createElement('div');
  div.setAttribute('style', 'position: absolute; top: 0, left:0; width:0, height:0, overflow: hidden; visibility: hidden;');
  div.innerHTML = popover.getAttribute('data-content');

  var has_math = div.querySelector("span.math");
  if (has_math) {
    document.body.appendChild(div);
    MathJax.Hub.Queue(["Typeset", MathJax.Hub, div]);
    MathJax.Hub.Queue(function() {
      popover.setAttribute('data-content', div.innerHTML);
      document.body.removeChild(div);
    })
  }
}
</script>
</body>
</html>

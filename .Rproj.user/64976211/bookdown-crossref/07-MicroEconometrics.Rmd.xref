h1:binary-choice-models Binary-choice models
fig:LPM Fitting a binary variable with a linear model (Linear Probability Model, LPM). The model is $\\mathbb{P}(y_i=1|x_i)=\\Phi(0.5+2x_i)$, where $\\Phi$ is the c.d.f. of the normal distribution and where $x_i \\sim \\,i.i.d.\\,\\mathcal{N}(0,1)$.
tab:foo This table provides examples of function , s.t. . The LPM case (last row) is given for comparison but, again, it does not satisfy  for any value of .
fig:ProbLogit Probit, Logit, and Log-log functions.
fig:LPM2 The model is $\\mathbb{P}(y_i=1|x_i)=\\Phi(0.5+2x_i)$, where $\\Phi$ is the c.d.f. of the normal distribution and where $x_i \\sim \\,i.i.d.\\,\\mathcal{N}(0,1)$. Crosses give the model-implied probabilities of having $y_i=1$ (conditional on $x_i$).
h2:latent Interpretation in terms of latent variable, and utility-based models
fig:Latent Distribution of $y_i^*$ conditional on $\\bv{x}_i$.
h2:Avregressors Alternative-Varying Regressors
h2:estimation Estimation
h2:marginalFX Marginal effects
h2:goodness-of-fit Goodness of fit
h2:predictions-and-roc-curves Predictions and ROC curves

